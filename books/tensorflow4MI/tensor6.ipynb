{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "image_batch = tf.constant([\n",
    "    [\n",
    "        [[0, 255, 0], [0, 255, 0], [0, 255, 0]],\n",
    "        [[0, 255, 0], [0, 255, 0], [0, 255, 0]]\n",
    "    ],\n",
    "    [\n",
    "        [[0, 255, 0], [0, 255, 0], [0, 255, 0]],\n",
    "        [[0, 255, 0], [0, 255, 0], [0, 255, 0]]\n",
    "    ]\n",
    "])\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print(image_batch.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0, 255,   0],\n",
       "         [  0, 255,   0],\n",
       "         [  0, 255,   0]],\n",
       "\n",
       "        [[  0, 255,   0],\n",
       "         [  0, 255,   0],\n",
       "         [  0, 255,   0]]],\n",
       "\n",
       "\n",
       "       [[[  0, 255,   0],\n",
       "         [  0, 255,   0],\n",
       "         [  0, 255,   0]],\n",
       "\n",
       "        [[  0, 255,   0],\n",
       "         [  0, 255,   0],\n",
       "         [  0, 255,   0]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(image_batch)[0]\n",
    "sess.run(image_batch)[0][0]\n",
    "sess.run(image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input and kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_batch = tf.constant([\n",
    "    [\n",
    "        [[0.0], [1.0]],\n",
    "        [[2.0], [3.0]]\n",
    "    ],\n",
    "    [\n",
    "        [[2.0], [4.0]],\n",
    "        [[6.0], [8.0]]\n",
    "    ]\n",
    "])\n",
    "kernel = tf.constant([\n",
    "    [\n",
    "        [[1.0, 2.0]]\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0.,   0.],\n",
       "         [  1.,   2.]],\n",
       "\n",
       "        [[  2.,   4.],\n",
       "         [  3.,   6.]]],\n",
       "\n",
       "\n",
       "       [[[  2.,   4.],\n",
       "         [  4.,   8.]],\n",
       "\n",
       "        [[  6.,  12.],\n",
       "         [  8.,  16.]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1,1,1,1], padding=\"SAME\")\n",
    "sess.run(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2, 1)\n",
      "(2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(input_batch.get_shape())\n",
    "print(_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### strides\n",
    "\n",
    "useful to skip some points and reduce the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 2.20000005],\n",
       "         [ 4.19999981],\n",
       "         [ 6.19999981],\n",
       "         [ 8.19999981]],\n",
       "\n",
       "        [[ 2.4000001 ],\n",
       "         [ 4.4000001 ],\n",
       "         [ 6.4000001 ],\n",
       "         [ 8.39999962]],\n",
       "\n",
       "        [[ 2.5999999 ],\n",
       "         [ 4.60000038],\n",
       "         [ 6.60000038],\n",
       "         [ 8.60000038]],\n",
       "\n",
       "        [[ 2.79999995],\n",
       "         [ 4.80000019],\n",
       "         [ 6.80000019],\n",
       "         [ 8.80000019]]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch = tf.constant([\n",
    "    [\n",
    "        [[0.0], [1.0], [2.0], [3.0], [4.0], [5.0]],\n",
    "        [[0.1], [1.1], [2.1], [3.1], [4.1], [5.1]],\n",
    "        [[0.2], [1.2], [2.2], [3.2], [4.2], [5.2]],\n",
    "        [[0.3], [1.3], [2.3], [3.3], [4.3], [5.3]],\n",
    "        [[0.4], [1.4], [2.4], [3.4], [4.4], [5.4]],\n",
    "        [[0.5], [1.5], [2.5], [3.5], [4.5], [5.5]],\n",
    "    ],\n",
    "])\n",
    "\n",
    "kernel = tf.constant([\n",
    "    [[[0.0]], [[0.5]], [[0.0]]],\n",
    "    [[[0.0]], [[1.0]], [[0.0]]],\n",
    "    [[[0.0]], [[0.5]], [[0.0]]],\n",
    "])\n",
    "\n",
    "conv2d = tf.nn.conv2d(input_batch, kernel, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "sess.run(conv2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding\n",
    "\n",
    "Filling the missing area of the image.\n",
    "In practice, \"VALID\" is preferred if it is the best, nor the \"SAME\" can be used to fit other situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Layers\n",
    "\n",
    "###### tf.nn.depthwise_conv2d: \n",
    "attaching the output of one convolution to the input of another convolution layer\n",
    "\n",
    "###### tf.nn.separable_conv2d: \n",
    "it speeds up training without sacrificing accuracy. For small models, it will converge quickly with worse accuracy \n",
    "\n",
    "###### tf.nn.conv2d_transpose: \n",
    "This applies a kernel to a new feature map where each section is filled with the same values as the kernel. As the kernel strides over the new image, any overlapping sections are summed together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "the activation functions must meet two conditions:\n",
    "###### monotonic 单调的\n",
    "###### differentiable 可导的\n",
    "\n",
    "\n",
    "##### tf.nn.relu\n",
    "ReLU suffer from neurons becoming saturated when too high of a learning rate is used\n",
    "\n",
    "##### tf.nn.sigmoid\n",
    "The reduced range of output values can cause trouble with input becoming saturated and changes in input becoming\n",
    "exaggerated\n",
    "\n",
    "##### tf.tanh\n",
    "双曲正切函数，S型曲线，取值范围为[-1.0, 1.0]\n",
    "\n",
    "\n",
    "##### tf.nn.dropout\n",
    "This layer performs well in scenarios where a little randomness helps training. An example scenario is when there are patterns being learned that are too tied to their neighboring features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.1,  0. ,  0.1,  0.2], dtype=float32),\n",
       " array([-0.2,  0. ,  0.2,  0. ], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf.constant([-0.1, 0.0, 0.1, 0.2])\n",
    "sess.run([features, tf.nn.dropout(features, keep_prob=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "Pooling layers reduce over-fitting and improving performance by reducing the size of\n",
    "the input.\n",
    "\n",
    "##### tf.nn.max_pool \n",
    "Useful when the intensity of the input data is relevant to importance in the image\n",
    "2x2 max-pooling operation is common used\n",
    "\n",
    "##### tf.nn.avg_pool\n",
    "Useful when reducing values where the entire kernel is important, for example, input tensors with a large width and height but small depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.81111115]]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "input_height = 3\n",
    "input_width = 3\n",
    "input_channels = 1\n",
    "\n",
    "layer_input = tf.constant([\n",
    "    [\n",
    "        [[1.0], [0.2], [1.5]],\n",
    "        [[0.1], [1.2], [1.4]],\n",
    "        [[1.1], [0.4], [0.4]]\n",
    "    ]\n",
    "])\n",
    "\n",
    "kernel = [batch_size, input_height, input_width, input_channels]\n",
    "max_pool = tf.nn.max_pool(layer_input, kernel, [1,1,1,1], \"VALID\")\n",
    "sess.run(max_pool)\n",
    "\n",
    "avg_pool = tf.nn.avg_pool(layer_input, kernel, [1,1,1,1], \"VALID\")\n",
    "sess.run(avg_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Often useful to utilize some form of normalization to identify high-frequency features.\n",
    "\n",
    "\n",
    "##### tf.nn.local_response_normalization (tf.nn.lrn)\n",
    "Local response normalization normalizes values while taking into account the significance of each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 2.]],\n",
       " \n",
       "         [[ 3.]]]], dtype=float32), array([[[[ 0.70710677]],\n",
       " \n",
       "         [[ 0.89442718]],\n",
       " \n",
       "         [[ 0.94868326]]]], dtype=float32)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_input = tf.constant([\n",
    "    [[[1.]], [[2.]], [[3.]]]\n",
    "])\n",
    "\n",
    "lrn = tf.nn.local_response_normalization(layer_input)\n",
    "sess.run([layer_input, lrn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level Layers\n",
    "useful to avoid duplicate code while following best practices\n",
    "\n",
    "##### tf.contrib.layers.convolution2d\n",
    "a wrapper for tf.conv2d\n",
    "\n",
    "##### tf.contrib.layers.fully_connected\n",
    " for CNNs, the last layer is quite often fully connected. The tf.contrib.layers.fully_connected layer offers a great short-hand to create this last layer while following best practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "         [   0.        ,  308.15246582,  161.81060791,   45.64549255],\n",
       "         [   0.        ,   14.6790638 ,   73.46196747,    0.        ]],\n",
       "\n",
       "        [[ 171.01591492,  143.91101074,    0.        ,   19.55454254],\n",
       "         [  38.12561798,  174.09210205,  151.00965881,  174.52609253],\n",
       "         [ 171.01591492,  143.91101074,    0.        ,   19.55454254]],\n",
       "\n",
       "        [[   0.        ,   14.6790638 ,   73.46196747,    0.        ],\n",
       "         [   0.        ,  308.15246582,  161.81060791,   45.64549255],\n",
       "         [   0.        ,    0.        ,    0.        ,    0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input = tf.constant([\n",
    "    [\n",
    "        [[0., 0., 0.], [255., 255., 255.], [254., 0., 0.]],\n",
    "        [[0., 191., 0.], [3., 108., 233.], [0., 191., 0.]],\n",
    "        [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.]]\n",
    "    ]\n",
    "])\n",
    "\n",
    "conv2d = tf.contrib.layers.convolution2d(\n",
    "    image_input, \n",
    "    num_outputs=4,\n",
    "    kernel_size=(1,1),\n",
    "    activation_fn=tf.nn.relu,\n",
    "    stride=(1,1),\n",
    "    trainable=True\n",
    ")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17464128,  1.00942397],\n",
       "       [ 0.49481696,  2.8600347 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf.constant(\n",
    "    [[1.2], [3.4]]\n",
    ")\n",
    "fc = tf.contrib.layers.fully_connected(features, num_outputs=2)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(fc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
